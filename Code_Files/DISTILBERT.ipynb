{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('/home/nalin21478/BTP/ML-food-Processing/Numerical_Textual_ML/Data/65_Nuts.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Main_food_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# Assuming data is your DataFrame containing both categorical and numerical data\n",
    "\n",
    "# Step 1: Separate Categorical and Numerical Data\n",
    "categorical_data = data.select_dtypes(include=['object'])\n",
    "numerical_data = data.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Initialize DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "\n",
    "# Separate Categorical and Numerical Data\n",
    "categorical_data = data.select_dtypes(include=['object'])\n",
    "numerical_data = data.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Initialize DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Function to tokenize and obtain embeddings for a single value\n",
    "def get_embeddings(value):\n",
    "    inputs = tokenizer(value, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = torch.mean(outputs.last_hidden_state, dim=1).squeeze().detach().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Function to obtain embeddings for each value in a categorical column\n",
    "def get_column_embeddings(column):\n",
    "    embeddings_list = []\n",
    "    for value in column:\n",
    "        embeddings = get_embeddings(value)\n",
    "        embeddings_list.append(embeddings)\n",
    "    return embeddings_list\n",
    "\n",
    "# Dictionary to store aggregated embeddings for each categorical column\n",
    "categorical_embeddings_aggregated = {}\n",
    "\n",
    "# Generate Word Embeddings for Categorical Data\n",
    "for col in categorical_data.columns:\n",
    "    print(f'Obtaining embeddings for {col}...')\n",
    "    # Obtain embeddings for values in the column\n",
    "    embeddings = get_column_embeddings(categorical_data[col])\n",
    "    # Aggregate embeddings (e.g., average pooling)\n",
    "    aggregated_embeddings = np.mean(embeddings, axis=0)\n",
    "    # Store aggregated embeddings in the dictionary\n",
    "    categorical_embeddings_aggregated[col] = aggregated_embeddings\n",
    "\n",
    "# Convert categorical_embeddings_aggregated dictionary to DataFrame\n",
    "categorical_embeddings_df = pd.DataFrame(categorical_embeddings_aggregated)\n",
    "\n",
    "\n",
    "\n",
    "## Combine Numerical and Categorical Data with Embeddings\n",
    "data_with_embeddings = pd.concat([numerical_data.reset_index(drop=True), categorical_embeddings_df.reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catnumb</th>\n",
       "      <th>novaclass</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Total Fat</th>\n",
       "      <th>Carbohydrate</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Water</th>\n",
       "      <th>Caffeine</th>\n",
       "      <th>Theobromine</th>\n",
       "      <th>...</th>\n",
       "      <th>18:4</th>\n",
       "      <th>20:1</th>\n",
       "      <th>20:5 n-3</th>\n",
       "      <th>22:1</th>\n",
       "      <th>22:5 n-3</th>\n",
       "      <th>Fatty acids, total monounsaturated</th>\n",
       "      <th>Fatty acids, total polyunsaturated</th>\n",
       "      <th>Main_food_description</th>\n",
       "      <th>catname</th>\n",
       "      <th>macroclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9602</td>\n",
       "      <td>1</td>\n",
       "      <td>1.03</td>\n",
       "      <td>4.38</td>\n",
       "      <td>6.89</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.658</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.092892</td>\n",
       "      <td>0.161031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1.91</td>\n",
       "      <td>4.85</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.028462</td>\n",
       "      <td>0.085337</td>\n",
       "      <td>-0.057516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.80</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.000871</td>\n",
       "      <td>-0.140204</td>\n",
       "      <td>-0.293136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.46</td>\n",
       "      <td>4.46</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.172098</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>0.052279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.24</td>\n",
       "      <td>4.79</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.201337</td>\n",
       "      <td>0.154887</td>\n",
       "      <td>-0.034462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>7802</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>7802</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>7804</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>7804</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.49</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>9204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2970 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      catnumb  novaclass  Protein  Total Fat  Carbohydrate  Energy  Alcohol  \\\n",
       "0        9602          1     1.03       4.38          6.89    70.0      0.0   \n",
       "1        1004          1     3.28       1.91          4.85    50.0      0.0   \n",
       "2        1002          1     3.15       3.25          4.80    61.0      0.0   \n",
       "3        1002          1     3.10       3.46          4.46    61.0      0.0   \n",
       "4        1002          1     3.14       3.24          4.79    61.0      0.0   \n",
       "...       ...        ...      ...        ...           ...     ...      ...   \n",
       "2965     7802          4     0.00       0.00          0.15     1.0      0.0   \n",
       "2966     7802          4     0.00       0.00          4.50    18.0      0.0   \n",
       "2967     7804          4     0.00       0.00          1.22     5.0      0.0   \n",
       "2968     7804          4     0.00       0.00          5.49    22.0      0.0   \n",
       "2969     9204          1     0.00       0.00          0.00     0.0      0.0   \n",
       "\n",
       "      Water  Caffeine  Theobromine  ...  18:4   20:1  20:5 n-3  22:1  \\\n",
       "0     87.50       0.0          0.0  ...   0.0  0.040       0.0   0.0   \n",
       "1     89.25       0.0          0.0  ...   0.0  0.001       0.0   0.0   \n",
       "2     88.13       0.0          0.0  ...   0.0  0.000       0.0   0.0   \n",
       "3     88.20       0.0          0.0  ...   0.0  0.000       0.0   0.0   \n",
       "4     87.87       0.0          0.0  ...   0.0  0.000       0.0   0.0   \n",
       "...     ...       ...          ...  ...   ...    ...       ...   ...   \n",
       "2965  99.85       0.0          0.0  ...   0.0  0.000       0.0   0.0   \n",
       "2966  94.44       0.0          0.0  ...   0.0  0.000       0.0   0.0   \n",
       "2967  98.78       0.0          0.0  ...   0.0  0.000       0.0   0.0   \n",
       "2968  94.44       0.0          0.0  ...   0.0  0.000       0.0   0.0   \n",
       "2969  99.98       0.0          0.0  ...   0.0  0.000       0.0   0.0   \n",
       "\n",
       "      22:5 n-3  Fatty acids, total monounsaturated  \\\n",
       "0          0.0                               1.658   \n",
       "1          0.0                               0.507   \n",
       "2          0.0                               0.812   \n",
       "3          0.0                               0.999   \n",
       "4          0.0                               0.810   \n",
       "...        ...                                 ...   \n",
       "2965       0.0                               0.000   \n",
       "2966       0.0                               0.000   \n",
       "2967       0.0                               0.000   \n",
       "2968       0.0                               0.000   \n",
       "2969       0.0                               0.000   \n",
       "\n",
       "      Fatty acids, total polyunsaturated  Main_food_description   catname  \\\n",
       "0                                  0.497               0.005968  0.092892   \n",
       "1                                  0.094               0.028462  0.085337   \n",
       "2                                  0.195              -0.000871 -0.140204   \n",
       "3                                  0.128               0.172098  0.191872   \n",
       "4                                  0.194               0.201337  0.154887   \n",
       "...                                  ...                    ...       ...   \n",
       "2965                               0.000               0.000000  0.000000   \n",
       "2966                               0.000               0.000000  0.000000   \n",
       "2967                               0.000               0.000000  0.000000   \n",
       "2968                               0.000               0.000000  0.000000   \n",
       "2969                               0.000               0.000000  0.000000   \n",
       "\n",
       "      macroclass  \n",
       "0       0.161031  \n",
       "1      -0.057516  \n",
       "2      -0.293136  \n",
       "3       0.052279  \n",
       "4      -0.034462  \n",
       "...          ...  \n",
       "2965    0.000000  \n",
       "2966    0.000000  \n",
       "2967    0.000000  \n",
       "2968    0.000000  \n",
       "2969    0.000000  \n",
       "\n",
       "[2970 rows x 70 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "novaclass\n",
       "4    2112\n",
       "3     466\n",
       "1     339\n",
       "2      53\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_embeddings[\"novaclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9259259259259259\n",
      "Confusion Matrix:\n",
      "[[ 62   0   4   2]\n",
      " [  0   6   0   2]\n",
      " [  5   0  71  11]\n",
      " [  6   5   9 411]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.91      0.88        68\n",
      "           2       0.55      0.75      0.63         8\n",
      "           3       0.85      0.82      0.83        87\n",
      "           4       0.96      0.95      0.96       431\n",
      "\n",
      "    accuracy                           0.93       594\n",
      "   macro avg       0.80      0.86      0.83       594\n",
      "weighted avg       0.93      0.93      0.93       594\n",
      "\n",
      "F1 Score (weighted): 0.9267635752587424\n",
      "Matthews Correlation Coefficient: 0.8336403847944476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming you have a target column named 'novaclass' in your original DataFrame\n",
    "# Split data into features (X) and target (y)\n",
    "X = data_with_embeddings.drop(columns=['novaclass'])  # Features\n",
    "y = data_with_embeddings['novaclass']  # Target\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "# Apply SMOTE to the training data after handling missing values\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print F1 score and Matthews correlation coefficient\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.930976430976431\n",
      "Confusion Matrix:\n",
      "[[ 61   0   5   2]\n",
      " [  0   6   0   2]\n",
      " [  6   0  72   9]\n",
      " [  7   3   7 414]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.90      0.86        68\n",
      "           2       0.67      0.75      0.71         8\n",
      "           3       0.86      0.83      0.84        87\n",
      "           4       0.97      0.96      0.97       431\n",
      "\n",
      "    accuracy                           0.93       594\n",
      "   macro avg       0.83      0.86      0.84       594\n",
      "weighted avg       0.93      0.93      0.93       594\n",
      "\n",
      "F1 Score (weighted): 0.9314188920195349\n",
      "Matthews Correlation Coefficient: 0.844479188769997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nalin21478/miniconda3/envs/torch/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but ExtraTreesClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "# Initialize and train an ExtraTreesClassifier\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "et_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = et_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print F1 score and Matthews correlation coefficient\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16273\n",
      "[LightGBM] [Info] Number of data points in the train set: 6724, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.930976430976431\n",
      "Confusion Matrix:\n",
      "[[ 63   0   3   2]\n",
      " [  1   6   0   1]\n",
      " [  6   0  68  13]\n",
      " [  6   2   7 416]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.93      0.88        68\n",
      "           2       0.75      0.75      0.75         8\n",
      "           3       0.87      0.78      0.82        87\n",
      "           4       0.96      0.97      0.96       431\n",
      "\n",
      "    accuracy                           0.93       594\n",
      "   macro avg       0.85      0.86      0.85       594\n",
      "weighted avg       0.93      0.93      0.93       594\n",
      "\n",
      "F1 Score (weighted): 0.930516921736768\n",
      "Matthews Correlation Coefficient: 0.842896556492914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and train an LightGBM classifier\n",
    "lgbm_classifier = LGBMClassifier(random_state=42)\n",
    "lgbm_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lgbm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print F1 score and Matthews correlation coefficient\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9175084175084175\n",
      "Confusion Matrix:\n",
      "[[ 66   0   2   0]\n",
      " [  1   6   0   1]\n",
      " [  5   0  71  11]\n",
      " [  8   4  17 402]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.97      0.89        68\n",
      "           2       0.60      0.75      0.67         8\n",
      "           3       0.79      0.82      0.80        87\n",
      "           4       0.97      0.93      0.95       431\n",
      "\n",
      "    accuracy                           0.92       594\n",
      "   macro avg       0.80      0.87      0.83       594\n",
      "weighted avg       0.92      0.92      0.92       594\n",
      "\n",
      "F1 Score (weighted): 0.9189666096228462\n",
      "Matthews Correlation Coefficient: 0.8209853585063333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nalin21478/miniconda3/envs/torch/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Initialize and train a Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print F1 score and Matthews correlation coefficient\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9326599326599326\n",
      "Confusion Matrix:\n",
      "[[ 64   0   2   2]\n",
      " [  1   6   0   1]\n",
      " [  5   0  68  14]\n",
      " [  5   3   7 416]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.90        68\n",
      "           1       0.67      0.75      0.71         8\n",
      "           2       0.88      0.78      0.83        87\n",
      "           3       0.96      0.97      0.96       431\n",
      "\n",
      "    accuracy                           0.93       594\n",
      "   macro avg       0.84      0.86      0.85       594\n",
      "weighted avg       0.93      0.93      0.93       594\n",
      "\n",
      "F1 Score (weighted): 0.932150791567532\n",
      "Matthews Correlation Coefficient: 0.8464839012170764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "y_train_xg=y_train-1\n",
    "y_test_xg=y_test-1\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "# Apply SMOTE to the training data after handling missing values\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_xg)\n",
    "\n",
    "# Initialize and train a XGBoost Classifier\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_xg, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_xg, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_xg, y_pred))\n",
    "\n",
    "# Print F1 score and Matthews correlation coefficient\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test_xg, y_pred, average='weighted'))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test_xg, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.877104377104377\n",
      "Confusion Matrix:\n",
      "[[ 55   0   8   5]\n",
      " [  1   5   0   2]\n",
      " [  8   0  63  16]\n",
      " [ 10   5  18 398]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.81      0.77        68\n",
      "           2       0.50      0.62      0.56         8\n",
      "           3       0.71      0.72      0.72        87\n",
      "           4       0.95      0.92      0.93       431\n",
      "\n",
      "    accuracy                           0.88       594\n",
      "   macro avg       0.72      0.77      0.75       594\n",
      "weighted avg       0.88      0.88      0.88       594\n",
      "\n",
      "F1 Score (weighted): 0.8789157461176953\n",
      "Matthews Correlation Coefficient: 0.7269964168520642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Apply SMOTE to the training data after handling missing values\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize and train a Gradient Boosting Classifier\n",
    "gb_classifier = DecisionTreeClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print F1 score and Matthews correlation coefficient\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8922558922558923\n",
      "Confusion Matrix:\n",
      "[[ 64   0   4   0]\n",
      " [  0   7   1   0]\n",
      " [  8   0  73   6]\n",
      " [  9  11  25 386]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.94      0.86        68\n",
      "           2       0.39      0.88      0.54         8\n",
      "           3       0.71      0.84      0.77        87\n",
      "           4       0.98      0.90      0.94       431\n",
      "\n",
      "    accuracy                           0.89       594\n",
      "   macro avg       0.72      0.89      0.78       594\n",
      "weighted avg       0.91      0.89      0.90       594\n",
      "\n",
      "F1 Score (weighted): 0.8987677564108959\n",
      "Matthews Correlation Coefficient: 0.782625437865471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and train a Gradient Boosting Classifier\n",
    "gb_classifier = KNeighborsClassifier()\n",
    "gb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print F1 score and Matthews correlation coefficient\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7575757575757576\n",
      "Confusion Matrix:\n",
      "[[ 38   8  21   1]\n",
      " [  0   7   0   1]\n",
      " [  3   7  74   3]\n",
      " [  4  69  27 331]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.56      0.67        68\n",
      "           2       0.08      0.88      0.14         8\n",
      "           3       0.61      0.85      0.71        87\n",
      "           4       0.99      0.77      0.86       431\n",
      "\n",
      "    accuracy                           0.76       594\n",
      "   macro avg       0.63      0.76      0.60       594\n",
      "weighted avg       0.90      0.76      0.81       594\n",
      "\n",
      "F1 Score (weighted): 0.8088735258352057\n",
      "Matthews Correlation Coefficient: 0.5927561380550449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Initialize and train a Gradient Boosting Classifier\n",
    "gb_classifier = MLPClassifier()\n",
    "gb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print F1 score and Matthews correlation coefficient\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5959595959595959\n",
      "Confusion Matrix:\n",
      "[[ 61   4   3   0]\n",
      " [  3   4   1   0]\n",
      " [ 21   7  52   7]\n",
      " [ 36  61  97 237]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.90      0.65        68\n",
      "           2       0.05      0.50      0.10         8\n",
      "           3       0.34      0.60      0.43        87\n",
      "           4       0.97      0.55      0.70       431\n",
      "\n",
      "    accuracy                           0.60       594\n",
      "   macro avg       0.47      0.64      0.47       594\n",
      "weighted avg       0.81      0.60      0.65       594\n",
      "\n",
      "F1 Score (weighted): 0.6481714855788929\n",
      "Matthews Correlation Coefficient: 0.4221546194338563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nalin21478/miniconda3/envs/torch/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and train a Gradient Boosting Classifier\n",
    "gb_classifier = LogisticRegression()\n",
    "gb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print F1 score and Matthews correlation coefficient\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_embeddings.to_csv('/home/nalin21478/BTP/ML-food-Processing/Numerical_Textual_ML/Data/65 Nuts/65_Nuts_Embeddings_DistilBert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
